OptiTrack Interface to ROS
=====


Intro
----

Getting positions of objects in the observable OptiTrack space to ROS works as follows. The OptiTrack cameras send out pulsed infrared light using the
attached infrared LEDs, which will then be reflected by markers on the object and detected by the OptiTrack cameras, provided the markers are in the field of view of the cameras. Knowing the position of those markers in perspective of several cameras, the actual 3D position of the markers in the room can be calculated using triangulation. By allocating several markers to a rigid body, an orientation of this body can be assigned. More info on Indoor Navigation -> System Architecture `page <http://risc.readthedocs.io/en/latest/2-1.html>`_.

Required Hardware
----

* Mocap machine. Runs Motive Motion Capture Software.
* Optitrack Motion Capture System
* WiFi router (5GHz recommended)
* A linux based computer, normal PC or onboard embedded computer like ODROID XU4 will work. The linux computer should be connected to the router either via ethernet cable or WiFi connection.

.. note::

	It is recommended that you use *static IP* for your linux machine, like follow:

	IP: 192.168.0.xxx

	Subnet Mask: 255.255.255.0

	Gateway: 192.168.0.1
	DNS Server: 8.8.8.8

Required Software
-----

* Motive. It allows you to calibrate your OptiTrack system, stream tracking information to external entities.

* ROS Kinetic installed on your Linux computer.

* `vrpn_client_ros <http://wiki.ros.org/vrpn_client_ros>`_ package for ROS to receive the tracking data from the Mocap computer.


Installation
-----

Method 1. PC
^^^^^

Install `vrpn_client_ros <http://wiki.ros.org/vrpn_client_ros>`_ using following command.

.. code-block:: bash

	sudo apt-get install ros-kinetic-vrpn-client-ros -y


Method 2. Odroid XU4
^^^^^

Flash `Ubuntu 16 with ROS Kinetic minimal <https://www.dropbox.com/s/bllrihqe9k8rtn9/ubuntu16_minimal_ros_kinetic_mavros.img?dl=0>`_ or `Ubuntu 16 Full with GUI <https://www.dropbox.com/s/gybc65tbct4d68b/ubuntu16_full_ros_kinetic.img?dl=0>`_. It's recommended to use minimal image.

It's recommended to use `Etcher <https://etcher.io/>`_ to flash your abovementioned images to ODROID eMMC/SD card.

No need to install `vrpn_client_ros <http://wiki.ros.org/vrpn_client_ros>`_ package as it's already included**


.. warning::
	
	In Motive, make sure you are streaming VRPN data by going to View > Streaming > Check the box in front of Stream VRPN Data. Lastly, make sure you either turn off the Windows Firewall or create outbound rules for the VRPN port (recommended).



.. image:: ../_static/motivecapture.PNG
   :scale: 50 %
   :align: center

Streaming MOCAP Data
-----

Now, you should be set to get data from mocap to your ROS.

1. Make sure that you installed ``vrpn_client_ros`` package. *All required packages are already included in the minimal ubuntu image referenced above*
2. If you are streaming data to an ODROID which is connected to a flight controller, make sure that you have ``mavros`` installed. See **next tutorial** to know how feed mocap data to Pixhawk that is connected to ODROID.
3. Make sure that you configured your Motive as mentioned above
4. Connect the PC that runs Motive to your router with an ethernet cable
5. Note down the IP address given to the Motive PC, let's call it ``motive_ip``
6. Create a rigid body in Motive and give it a proper name e.g. ``uav1``

.. error::

	If your rigid body has white spaces in its name e.g. ``robot 1``, the ROS mocap node will not receive it and will give errors

7. In your ROS machine, where you want to get tracking data, run the ``vrpn_client_ros`` node as follows

.. code-block:: bash

	roslaunch vrpn_client_ros sample.launch server:=<motive_ip>

8. Now you should be able to receive mocap data under topics that look like ``/vrpn_client_node/<rigid_body_name>/pose``